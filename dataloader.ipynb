{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78265c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'img_00091.jpg ,60.13121032714844 92.90408325195312 0.9837533831596375 ,52.727874755859375 103.09432983398438 1.0999332666397095 ,52.98760986328125 84.64228820800781 1.0287318229675293 ,60.1942138671875 116.5445556640625 0.9749239087104797 ,60.787384033203125 73.67532348632812 0.9833741188049316 ,112.78359985351562 139.41110229492188 1.001111626625061 ,112.98818969726562 55.78285217285156 1.0040918588638306 ,192.03021240234375 149.42005920410156 0.7704830169677734 ,191.98126220703125 42.03474426269531 0.8634825944900513 ,193.52606201171875 145.5717315673828 0.07413303107023239 ,193.52020263671875 39.55767822265625 0.1454618126153946 ,193.51556396484375 117.64739990234375 0.06861644983291626 ,193.522705078125 69.82029724121094 0.08380355685949326 ,193.5238037109375 -2.0425567626953125 0.038773953914642334 ,108.1351318359375 92.18673706054688 0.03272699937224388 ,193.51971435546875 151.5338897705078 0.04092157632112503 ,193.52301025390625 43.57696533203125 0.0669620931148529 , 32 66, 88 123, 89 137, 201 249, -16 137, 95 249, 30 36, 222 228'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81025476",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = [l for l in line.replace(',',\"\").split(' ') if l != '' and l != '\\n']\n",
    "imgpath = line[0]\n",
    "line = line[1:]\n",
    "line = [float(l) for l in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0ca07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.13121032714844,\n",
       " 92.90408325195312,\n",
       " 0.9837533831596375,\n",
       " 52.727874755859375,\n",
       " 103.09432983398438,\n",
       " 1.0999332666397095,\n",
       " 52.98760986328125,\n",
       " 84.64228820800781,\n",
       " 1.0287318229675293,\n",
       " 60.1942138671875,\n",
       " 116.5445556640625,\n",
       " 0.9749239087104797,\n",
       " 60.787384033203125,\n",
       " 73.67532348632812,\n",
       " 0.9833741188049316,\n",
       " 112.78359985351562,\n",
       " 139.41110229492188,\n",
       " 1.001111626625061,\n",
       " 112.98818969726562,\n",
       " 55.78285217285156,\n",
       " 1.0040918588638306,\n",
       " 192.03021240234375,\n",
       " 149.42005920410156,\n",
       " 0.7704830169677734,\n",
       " 191.98126220703125,\n",
       " 42.03474426269531,\n",
       " 0.8634825944900513,\n",
       " 193.52606201171875,\n",
       " 145.5717315673828,\n",
       " 0.07413303107023239,\n",
       " 193.52020263671875,\n",
       " 39.55767822265625,\n",
       " 0.1454618126153946,\n",
       " 193.51556396484375,\n",
       " 117.64739990234375,\n",
       " 0.06861644983291626,\n",
       " 193.522705078125,\n",
       " 69.82029724121094,\n",
       " 0.08380355685949326,\n",
       " 193.5238037109375,\n",
       " -2.0425567626953125,\n",
       " 0.038773953914642334,\n",
       " 108.1351318359375,\n",
       " 92.18673706054688,\n",
       " 0.03272699937224388,\n",
       " 193.51971435546875,\n",
       " 151.5338897705078,\n",
       " 0.04092157632112503,\n",
       " 193.52301025390625,\n",
       " 43.57696533203125,\n",
       " 0.0669620931148529,\n",
       " 32.0,\n",
       " 66.0,\n",
       " 88.0,\n",
       " 123.0,\n",
       " 89.0,\n",
       " 137.0,\n",
       " 201.0,\n",
       " 249.0,\n",
       " -16.0,\n",
       " 137.0,\n",
       " 95.0,\n",
       " 249.0,\n",
       " 30.0,\n",
       " 36.0,\n",
       " 222.0,\n",
       " 228.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960e6fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "        posepoints = line[0:51]\n",
    "        head = line[51:55]\n",
    "        lhand =line[55:59]\n",
    "        rhand = line[59:63]\n",
    "        bodybbox = line[63:]\n",
    "        pose_values = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b13ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.0, 36.0, 222.0, 228.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodybbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612bec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438544a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleFrames:\n",
    "    \"\"\"Sample frames from the video.\n",
    "    Required keys are \"total_frames\", \"start_index\" , added or modified keys\n",
    "    are \"frame_inds\", \"frame_interval\" and \"num_clips\".\n",
    "    Args:\n",
    "        clip_len (int): Frames of each sampled output clip.\n",
    "        frame_interval (int): Temporal interval of adjacent sampled frames.\n",
    "            Default: 1.\n",
    "        num_clips (int): Number of clips to be sampled. Default: 1.\n",
    "        temporal_jitter (bool): Whether to apply temporal jittering.\n",
    "            Default: False.\n",
    "        twice_sample (bool): Whether to use twice sample when testing.\n",
    "            If set to True, it will sample frames with and without fixed shift,\n",
    "            which is commonly used for testing in TSM model. Default: False.\n",
    "        out_of_bound_opt (str): The way to deal with out of bounds frame\n",
    "            indexes. Available options are 'loop', 'repeat_last'.\n",
    "            Default: 'loop'.\n",
    "        test_mode (bool): Store True when building test or validation dataset.\n",
    "            Default: False.\n",
    "        start_index (None): This argument is deprecated and moved to dataset\n",
    "            class (``BaseDataset``, ``VideoDataset``, ``RawframeDataset``,\n",
    "            etc), see this: https://github.com/open-mmlab/mmaction2/pull/89.\n",
    "        keep_tail_frames (bool): Whether to keep tail frames when sampling.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 clip_len,\n",
    "                 frame_interval=1,\n",
    "                 num_clips=1,\n",
    "                 temporal_jitter=False,\n",
    "                 twice_sample=False,\n",
    "                 out_of_bound_opt='loop',\n",
    "                 test_mode=False,\n",
    "                 start_index=None,\n",
    "                 keep_tail_frames=False):\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "        self.frame_interval = frame_interval\n",
    "        self.num_clips = num_clips\n",
    "        self.temporal_jitter = temporal_jitter\n",
    "        self.twice_sample = twice_sample\n",
    "        self.out_of_bound_opt = out_of_bound_opt\n",
    "        self.test_mode = test_mode\n",
    "        self.keep_tail_frames = keep_tail_frames\n",
    "        assert self.out_of_bound_opt in ['loop', 'repeat_last']\n",
    "\n",
    "        if start_index is not None:\n",
    "            warnings.warn('No longer support \"start_index\" in \"SampleFrames\", '\n",
    "                          'it should be set in dataset class, see this pr: '\n",
    "                          'https://github.com/open-mmlab/mmaction2/pull/89')\n",
    "\n",
    "    def _get_train_clips(self, num_frames):\n",
    "        \"\"\"Get clip offsets in train mode.\n",
    "        It will calculate the average interval for selected frames,\n",
    "        and randomly shift them within offsets between [0, avg_interval].\n",
    "        If the total number of frames is smaller than clips num or origin\n",
    "        frames length, it will return all zero indices.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices in train mode.\n",
    "        \"\"\"\n",
    "        ori_clip_len = self.clip_len * self.frame_interval\n",
    "\n",
    "        if self.keep_tail_frames:\n",
    "            avg_interval = (num_frames - ori_clip_len + 1) / float(\n",
    "                self.num_clips)\n",
    "            if num_frames > ori_clip_len - 1:\n",
    "                base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "                clip_offsets = (base_offsets + np.random.uniform(\n",
    "                    0, avg_interval, self.num_clips)).astype(int)\n",
    "            else:\n",
    "                clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "        else:\n",
    "            avg_interval = (num_frames - ori_clip_len + 1) // self.num_clips\n",
    "\n",
    "            if avg_interval > 0:\n",
    "                base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "                clip_offsets = base_offsets + np.random.randint(\n",
    "                    avg_interval, size=self.num_clips)\n",
    "            elif num_frames > max(self.num_clips, ori_clip_len):\n",
    "                clip_offsets = np.sort(\n",
    "                    np.random.randint(\n",
    "                        num_frames - ori_clip_len + 1, size=self.num_clips))\n",
    "            elif avg_interval == 0:\n",
    "                ratio = (num_frames - ori_clip_len + 1.0) / self.num_clips\n",
    "                clip_offsets = np.around(np.arange(self.num_clips) * ratio)\n",
    "            else:\n",
    "                clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "\n",
    "        return clip_offsets\n",
    "\n",
    "    def _get_test_clips(self, num_frames):\n",
    "        \"\"\"Get clip offsets in test mode.\n",
    "        Calculate the average interval for selected frames, and shift them\n",
    "        fixedly by avg_interval/2. If set twice_sample True, it will sample\n",
    "        frames together without fixed shift. If the total number of frames is\n",
    "        not enough, it will return all zero indices.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices in test mode.\n",
    "        \"\"\"\n",
    "        ori_clip_len = self.clip_len * self.frame_interval\n",
    "        avg_interval = (num_frames - ori_clip_len + 1) / float(self.num_clips)\n",
    "        if num_frames > ori_clip_len - 1:\n",
    "            base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "            clip_offsets = (base_offsets + avg_interval / 2.0).astype(int)\n",
    "            if self.twice_sample:\n",
    "                clip_offsets = np.concatenate([clip_offsets, base_offsets])\n",
    "        else:\n",
    "            clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "        return clip_offsets\n",
    "\n",
    "    def _sample_clips(self, num_frames):\n",
    "        \"\"\"Choose clip offsets for the video in a given mode.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices.\n",
    "        \"\"\"\n",
    "        if self.test_mode:\n",
    "            clip_offsets = self._get_test_clips(num_frames)\n",
    "        else:\n",
    "            clip_offsets = self._get_train_clips(num_frames)\n",
    "\n",
    "        return clip_offsets\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Perform the SampleFrames loading.\n",
    "        Args:\n",
    "            results (dict): The resulting dict to be modified and passed\n",
    "                to the next transform in pipeline.\n",
    "        \"\"\"\n",
    "        total_frames = results['total_frames']\n",
    "\n",
    "        clip_offsets = self._sample_clips(total_frames)\n",
    "        frame_inds = clip_offsets[:, None] + np.arange(\n",
    "            self.clip_len)[None, :] * self.frame_interval\n",
    "        frame_inds = np.concatenate(frame_inds)\n",
    "\n",
    "        if self.temporal_jitter:\n",
    "            perframe_offsets = np.random.randint(\n",
    "                self.frame_interval, size=len(frame_inds))\n",
    "            frame_inds += perframe_offsets\n",
    "\n",
    "        frame_inds = frame_inds.reshape((-1, self.clip_len))\n",
    "        if self.out_of_bound_opt == 'loop':\n",
    "            frame_inds = np.mod(frame_inds, total_frames)\n",
    "        elif self.out_of_bound_opt == 'repeat_last':\n",
    "            safe_inds = frame_inds < total_frames\n",
    "            unsafe_inds = 1 - safe_inds\n",
    "            last_ind = np.max(safe_inds * frame_inds, axis=1)\n",
    "            new_inds = (safe_inds * frame_inds + (unsafe_inds.T * last_ind).T)\n",
    "            frame_inds = new_inds\n",
    "        else:\n",
    "            raise ValueError('Illegal out_of_bound option.')\n",
    "\n",
    "        start_index = results['start_index']\n",
    "        frame_inds = np.concatenate(frame_inds) + start_index\n",
    "        results['frame_inds'] = frame_inds.astype(int)\n",
    "        results['clip_len'] = self.clip_len\n",
    "        results['frame_interval'] = self.frame_interval\n",
    "        results['num_clips'] = self.num_clips\n",
    "        return results\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = (f'{self.__class__.__name__}('\n",
    "                    f'clip_len={self.clip_len}, '\n",
    "                    f'frame_interval={self.frame_interval}, '\n",
    "                    f'num_clips={self.num_clips}, '\n",
    "                    f'temporal_jitter={self.temporal_jitter}, '\n",
    "                    f'twice_sample={self.twice_sample}, '\n",
    "                    f'out_of_bound_opt={self.out_of_bound_opt}, '\n",
    "                    f'test_mode={self.test_mode})')\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e4e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(clip_len=1)\n",
    "results['total_frames'] = 50\n",
    "results['start_index'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af10d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleframes = SampleFrames(clip_len=32,\n",
    "                           frame_interval=2,\n",
    "                           num_clips=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sampleframes(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c43bb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39, 41, 43, 45, 47, 49,  1,  3,  5,  7,  9, 11, 13])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['frame_inds']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataloader",
   "language": "python",
   "name": "dataloader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
