{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612bec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438544a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleFrames:\n",
    "    \"\"\"Sample frames from the video.\n",
    "    Required keys are \"total_frames\", \"start_index\" , added or modified keys\n",
    "    are \"frame_inds\", \"frame_interval\" and \"num_clips\".\n",
    "    Args:\n",
    "        clip_len (int): Frames of each sampled output clip.\n",
    "        frame_interval (int): Temporal interval of adjacent sampled frames.\n",
    "            Default: 1.\n",
    "        num_clips (int): Number of clips to be sampled. Default: 1.\n",
    "        temporal_jitter (bool): Whether to apply temporal jittering.\n",
    "            Default: False.\n",
    "        twice_sample (bool): Whether to use twice sample when testing.\n",
    "            If set to True, it will sample frames with and without fixed shift,\n",
    "            which is commonly used for testing in TSM model. Default: False.\n",
    "        out_of_bound_opt (str): The way to deal with out of bounds frame\n",
    "            indexes. Available options are 'loop', 'repeat_last'.\n",
    "            Default: 'loop'.\n",
    "        test_mode (bool): Store True when building test or validation dataset.\n",
    "            Default: False.\n",
    "        start_index (None): This argument is deprecated and moved to dataset\n",
    "            class (``BaseDataset``, ``VideoDataset``, ``RawframeDataset``,\n",
    "            etc), see this: https://github.com/open-mmlab/mmaction2/pull/89.\n",
    "        keep_tail_frames (bool): Whether to keep tail frames when sampling.\n",
    "            Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 clip_len,\n",
    "                 frame_interval=1,\n",
    "                 num_clips=1,\n",
    "                 temporal_jitter=False,\n",
    "                 twice_sample=False,\n",
    "                 out_of_bound_opt='loop',\n",
    "                 test_mode=False,\n",
    "                 start_index=None,\n",
    "                 keep_tail_frames=False):\n",
    "\n",
    "        self.clip_len = clip_len\n",
    "        self.frame_interval = frame_interval\n",
    "        self.num_clips = num_clips\n",
    "        self.temporal_jitter = temporal_jitter\n",
    "        self.twice_sample = twice_sample\n",
    "        self.out_of_bound_opt = out_of_bound_opt\n",
    "        self.test_mode = test_mode\n",
    "        self.keep_tail_frames = keep_tail_frames\n",
    "        assert self.out_of_bound_opt in ['loop', 'repeat_last']\n",
    "\n",
    "        if start_index is not None:\n",
    "            warnings.warn('No longer support \"start_index\" in \"SampleFrames\", '\n",
    "                          'it should be set in dataset class, see this pr: '\n",
    "                          'https://github.com/open-mmlab/mmaction2/pull/89')\n",
    "\n",
    "    def _get_train_clips(self, num_frames):\n",
    "        \"\"\"Get clip offsets in train mode.\n",
    "        It will calculate the average interval for selected frames,\n",
    "        and randomly shift them within offsets between [0, avg_interval].\n",
    "        If the total number of frames is smaller than clips num or origin\n",
    "        frames length, it will return all zero indices.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices in train mode.\n",
    "        \"\"\"\n",
    "        ori_clip_len = self.clip_len * self.frame_interval\n",
    "\n",
    "        if self.keep_tail_frames:\n",
    "            avg_interval = (num_frames - ori_clip_len + 1) / float(\n",
    "                self.num_clips)\n",
    "            if num_frames > ori_clip_len - 1:\n",
    "                base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "                clip_offsets = (base_offsets + np.random.uniform(\n",
    "                    0, avg_interval, self.num_clips)).astype(int)\n",
    "            else:\n",
    "                clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "        else:\n",
    "            avg_interval = (num_frames - ori_clip_len + 1) // self.num_clips\n",
    "\n",
    "            if avg_interval > 0:\n",
    "                base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "                clip_offsets = base_offsets + np.random.randint(\n",
    "                    avg_interval, size=self.num_clips)\n",
    "            elif num_frames > max(self.num_clips, ori_clip_len):\n",
    "                clip_offsets = np.sort(\n",
    "                    np.random.randint(\n",
    "                        num_frames - ori_clip_len + 1, size=self.num_clips))\n",
    "            elif avg_interval == 0:\n",
    "                ratio = (num_frames - ori_clip_len + 1.0) / self.num_clips\n",
    "                clip_offsets = np.around(np.arange(self.num_clips) * ratio)\n",
    "            else:\n",
    "                clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "\n",
    "        return clip_offsets\n",
    "\n",
    "    def _get_test_clips(self, num_frames):\n",
    "        \"\"\"Get clip offsets in test mode.\n",
    "        Calculate the average interval for selected frames, and shift them\n",
    "        fixedly by avg_interval/2. If set twice_sample True, it will sample\n",
    "        frames together without fixed shift. If the total number of frames is\n",
    "        not enough, it will return all zero indices.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices in test mode.\n",
    "        \"\"\"\n",
    "        ori_clip_len = self.clip_len * self.frame_interval\n",
    "        avg_interval = (num_frames - ori_clip_len + 1) / float(self.num_clips)\n",
    "        if num_frames > ori_clip_len - 1:\n",
    "            base_offsets = np.arange(self.num_clips) * avg_interval\n",
    "            clip_offsets = (base_offsets + avg_interval / 2.0).astype(int)\n",
    "            if self.twice_sample:\n",
    "                clip_offsets = np.concatenate([clip_offsets, base_offsets])\n",
    "        else:\n",
    "            clip_offsets = np.zeros((self.num_clips, ), dtype=int)\n",
    "        return clip_offsets\n",
    "\n",
    "    def _sample_clips(self, num_frames):\n",
    "        \"\"\"Choose clip offsets for the video in a given mode.\n",
    "        Args:\n",
    "            num_frames (int): Total number of frame in the video.\n",
    "        Returns:\n",
    "            np.ndarray: Sampled frame indices.\n",
    "        \"\"\"\n",
    "        if self.test_mode:\n",
    "            clip_offsets = self._get_test_clips(num_frames)\n",
    "        else:\n",
    "            clip_offsets = self._get_train_clips(num_frames)\n",
    "\n",
    "        return clip_offsets\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Perform the SampleFrames loading.\n",
    "        Args:\n",
    "            results (dict): The resulting dict to be modified and passed\n",
    "                to the next transform in pipeline.\n",
    "        \"\"\"\n",
    "        total_frames = results['total_frames']\n",
    "\n",
    "        clip_offsets = self._sample_clips(total_frames)\n",
    "        frame_inds = clip_offsets[:, None] + np.arange(\n",
    "            self.clip_len)[None, :] * self.frame_interval\n",
    "        frame_inds = np.concatenate(frame_inds)\n",
    "\n",
    "        if self.temporal_jitter:\n",
    "            perframe_offsets = np.random.randint(\n",
    "                self.frame_interval, size=len(frame_inds))\n",
    "            frame_inds += perframe_offsets\n",
    "\n",
    "        frame_inds = frame_inds.reshape((-1, self.clip_len))\n",
    "        if self.out_of_bound_opt == 'loop':\n",
    "            frame_inds = np.mod(frame_inds, total_frames)\n",
    "        elif self.out_of_bound_opt == 'repeat_last':\n",
    "            safe_inds = frame_inds < total_frames\n",
    "            unsafe_inds = 1 - safe_inds\n",
    "            last_ind = np.max(safe_inds * frame_inds, axis=1)\n",
    "            new_inds = (safe_inds * frame_inds + (unsafe_inds.T * last_ind).T)\n",
    "            frame_inds = new_inds\n",
    "        else:\n",
    "            raise ValueError('Illegal out_of_bound option.')\n",
    "\n",
    "        start_index = results['start_index']\n",
    "        frame_inds = np.concatenate(frame_inds) + start_index\n",
    "        results['frame_inds'] = frame_inds.astype(int)\n",
    "        results['clip_len'] = self.clip_len\n",
    "        results['frame_interval'] = self.frame_interval\n",
    "        results['num_clips'] = self.num_clips\n",
    "        return results\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = (f'{self.__class__.__name__}('\n",
    "                    f'clip_len={self.clip_len}, '\n",
    "                    f'frame_interval={self.frame_interval}, '\n",
    "                    f'num_clips={self.num_clips}, '\n",
    "                    f'temporal_jitter={self.temporal_jitter}, '\n",
    "                    f'twice_sample={self.twice_sample}, '\n",
    "                    f'out_of_bound_opt={self.out_of_bound_opt}, '\n",
    "                    f'test_mode={self.test_mode})')\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e4e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(clip_len=1)\n",
    "results['total_frames'] = 50\n",
    "results['start_index'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af10d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleframes = SampleFrames(clip_len=32,\n",
    "                           frame_interval=2,\n",
    "                           num_clips=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sampleframes(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c43bb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39, 41, 43, 45, 47, 49,  1,  3,  5,  7,  9, 11, 13])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['frame_inds']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wlasl)",
   "language": "python",
   "name": "wlasl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
